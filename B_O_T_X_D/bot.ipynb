{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import spacy as spc\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model init\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, input_dims, numOfKernels, numOfNeurons, kernelSize, numOfConvLayers, batchNorm):\n",
    "    super(CNN, self).__init__()         \n",
    "    self.numOfKernels = numOfKernels\n",
    "    self.batchNorm = batchNorm\n",
    "    self.numOfConvLayers = numOfConvLayers\n",
    "\n",
    "    # Convolutional Layers\n",
    "    self.conv1 = nn.Conv2d(3,numOfKernels, kernelSize)\n",
    "    self.conv2 = nn.Conv2d(numOfKernels,numOfKernels, kernelSize)\n",
    "    self.conv_BN = nn.BatchNorm2d(numOfKernels)\n",
    "\n",
    "    # Determine the output size after the convolutional layer\n",
    "    fullLayerSize_x = input_dims[1]\n",
    "    fullLayerSize_y = input_dims[0]\n",
    "    for i in range (self.numOfConvLayers):\n",
    "      fullLayerSize_x = (fullLayerSize_x-kernelSize+1)//2\n",
    "      fullLayerSize_y = (fullLayerSize_y-kernelSize+1)//2\n",
    "\n",
    "    # Error check the output size\n",
    "    if fullLayerSize_x <= 0 or fullLayerSize_y <= 0:\n",
    "      raise Exception(\"Too many convolutional layer for the input size, please decrease numOfConvLayers.\")\n",
    "\n",
    "    # Fully connected layers\n",
    "    self.fc1 = nn.Linear(numOfKernels*fullLayerSize_x*fullLayerSize_y, numOfNeurons)\n",
    "    self.fc1_BN = nn.BatchNorm1d(numOfNeurons)\n",
    "    self.pool = nn.MaxPool2d(2,2)\n",
    "    self.fc2 = nn.Linear(numOfNeurons, 6)\n",
    "    self.fc2_BN = nn.BatchNorm1d(6)\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.batchNorm == True:\n",
    "      x = self.pool(activation(self.conv_BN(self.conv1(x))))\n",
    "      for i in range (self.numOfConvLayers - 1):\n",
    "        x = self.pool(activation(self.conv_BN(self.conv2(x))))\n",
    "      x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "      x = activation(self.fc1_BN(self.fc1(x)))\n",
    "      x = self.fc2_BN(self.fc2(x))\n",
    "    else: \n",
    "      x = self.pool(activation(self.conv1(x)))\n",
    "      for i in range (self.numOfConvLayers - 1):\n",
    "        x = self.pool(activation(self.conv2(x)))\n",
    "      x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "      x = activation(self.fc1(x))\n",
    "      x = self.fc2(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Parameter Dict\n",
    "mdl = torch.load('mdl.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "there is my dad\n",
      "\n",
      "Model baseline: subjective (0.597)\n",
      "Model rnn: objective (0.006)\n",
      "Model cnn: objective (0.08)\n",
      "\n",
      "Enter a sentence\n",
      "An example output on the console is given below\n",
      "\n",
      "Model baseline: subjective (0.595)\n",
      "Model rnn: objective (0.034)\n",
      "Model cnn: objective (0.328)\n",
      "\n",
      "Enter a sentence\n",
      "I had a mental breakdown last week\n",
      "\n",
      "Model baseline: objective (0.077)\n",
      "Model rnn: objective (0.002)\n",
      "Model cnn: objective (0.022)\n",
      "\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n",
      "Please input a longer sentence... (4 word minimum)\n",
      "Enter a sentence\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-24f428086e54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter a sentence\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'~~'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# For testing and overall friendliness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\dev\\environments\\ece324\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\dev\\environments\\ece324\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Game Loop\n",
    "while True:\n",
    "    print(\"Enter a sentence\")\n",
    "    query = input()\n",
    "    if query == '~~': # For testing and overall friendliness\n",
    "        break\n",
    "    if len(query.split(' ')) < 4:\n",
    "        print(\"Please input a longer sentence... (4 word minimum)\")\n",
    "        continue\n",
    "    print(query)\n",
    "    print()\n",
    "    sentVec = [vocab.stoi[tok] for tok in tokenizer(query)]\n",
    "    sentTensor = torch.LongTensor(sentVec).view(-1, 1)\n",
    "    predbase = float(F.sigmoid(base(sentTensor)))\n",
    "    predrnn = float(F.sigmoid(rnn(sentTensor)[0]))\n",
    "    predcnn = float(F.sigmoid(cnn(sentTensor)))\n",
    "    print(\"Model baseline: {} ({})\".format(isObjective(predbase), round(predbase, 3)))\n",
    "    print(\"Model rnn: {} ({})\".format(isObjective(predrnn), round(predrnn, 3)))\n",
    "    print(\"Model cnn: {} ({})\".format(isObjective(predcnn), round(predcnn, 3)))\n",
    "    print()"
   ]
  }
 ]
}