{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "so63nxjaml6Y"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as pyplot\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import time\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS0gxwwuZoaL"
      },
      "source": [
        "# Hyperparameters\n",
        "numOfConvLayers = 4\n",
        "numOfKernels = 12\n",
        "numOfNeurons = 12\n",
        "learningRate = 0.1\n",
        "batchSize = 48\n",
        "test_split = 0.35\n",
        "numOfEpochs = 70\n",
        "kernelSize = 3\n",
        "activation = F.relu       \n",
        "optimizer_func = torch.optim.SGD\n",
        "loss_fnc = nn.CrossEntropyLoss()\n",
        "batchNorm = True\n",
        "numOfFCLayers = 2\n",
        "seed = 42\n",
        "\n",
        "# Input train, val, test dataset \n",
        "\n",
        "\n",
        "# CNN Model\n",
        "# Fixed Hyperparameters: square size image input, two fully connected layers\n",
        "# TODO: Error checking\n",
        "# TODO: testing \n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, input_dim, numOfKernels, numOfNeurons, kernelSize, numOfConvLayers, batchNorm):\n",
        "    super(CNN, self).__init__()         \n",
        "    self.numOfKernels = numOfKernels\n",
        "    self.batchNorm = batchNorm\n",
        "    self.numOfConvLayers = numOfConvLayers\n",
        "\n",
        "    # Convolutional Layers\n",
        "    self.conv1 = nn.Conv2d(3,numOfKernels, kernelSize)\n",
        "    self.conv2 = nn.Conv2d(numOfKernels,numOfKernels, kernelSize)\n",
        "    self.conv_BN = nn.BatchNorm2d(numOfKernels)\n",
        "\n",
        "    # Determine the output size after the convolutional layer\n",
        "    fullLayerSize = input_dim\n",
        "    for i in range (self.numOfConvLayers):\n",
        "      fullLayerSize = (fullLayerSize-kernelSize+1)//2\n",
        "\n",
        "    # Fully connected layers\n",
        "    self.fc1 = nn.Linear(numOfKernels*fullLayerSize*fullLayerSize, numOfNeurons)\n",
        "    self.fc1_BN = nn.BatchNorm1d(numOfNeurons)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.fc2 = nn.Linear(numOfNeurons, 6)\n",
        "    self.fc2_BN = nn.BatchNorm1d(6)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.batchNorm == True:\n",
        "      x = self.pool(activation(self.conv_BN(self.conv1(x))))\n",
        "      for i in range (self.numOfConvLayers - 1):\n",
        "        x = self.pool(activation(self.conv_BN(self.conv2(x))))\n",
        "      x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "      x = activation(self.fc1_BN(self.fc1(x)))\n",
        "      x = self.fc2_BN(self.fc2(x))\n",
        "    else: \n",
        "      x = self.pool(activation(self.conv1(x)))\n",
        "      for i in range (self.numOfConvLayers - 1):\n",
        "        x = self.pool(activation(self.conv2(x)))\n",
        "      x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "      x = activation(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "# Evaluation function \n",
        "\n",
        "\n",
        "# Train Overfit Model\n",
        "# def train_CNN_overfit(learningRate, vocab, num_filt, filter_size):\n",
        "#     torch.manual_seed(seed)\n",
        "#     model = CNN2(56, 8, 100, 3, 3, False))\n",
        "#     optimizer = optimizer_func(model.parameters(), lr=learningRate)\n",
        "#     return model, optimizer\n",
        "\n",
        "#Plotting"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}